{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28fc7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('../Downloads/Classified Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b56da5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.948\n",
      "Precision: 0.9481481481481482\n",
      "Recall: 0.9552238805970149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vusal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('../Downloads/Classified Data')\n",
    "data=df.copy()\n",
    "data\n",
    "\n",
    "# Extract the input features and target variable into separate arrays\n",
    "X = df.drop('TARGET CLASS', axis=1)\n",
    "y = df['TARGET CLASS']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Create a logistic regression model and fit it to the training data\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the accuracy score of the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d46d27e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.162073</td>\n",
       "      <td>0.567946</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.780862</td>\n",
       "      <td>0.352608</td>\n",
       "      <td>0.759697</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>1.231409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.635632</td>\n",
       "      <td>1.003722</td>\n",
       "      <td>0.535342</td>\n",
       "      <td>0.825645</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>0.648450</td>\n",
       "      <td>0.675334</td>\n",
       "      <td>1.013546</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>1.492702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.721360</td>\n",
       "      <td>1.201493</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>1.526629</td>\n",
       "      <td>0.720781</td>\n",
       "      <td>1.626351</td>\n",
       "      <td>1.154483</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>1.285597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.234204</td>\n",
       "      <td>1.386726</td>\n",
       "      <td>0.653046</td>\n",
       "      <td>0.825624</td>\n",
       "      <td>1.142504</td>\n",
       "      <td>0.875128</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>1.380003</td>\n",
       "      <td>1.522692</td>\n",
       "      <td>1.153093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.279491</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.627280</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>1.232537</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>1.115596</td>\n",
       "      <td>0.646691</td>\n",
       "      <td>1.463812</td>\n",
       "      <td>1.419167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>1.010953</td>\n",
       "      <td>1.034006</td>\n",
       "      <td>0.853116</td>\n",
       "      <td>0.622460</td>\n",
       "      <td>1.036610</td>\n",
       "      <td>0.586240</td>\n",
       "      <td>0.746811</td>\n",
       "      <td>0.319752</td>\n",
       "      <td>1.117340</td>\n",
       "      <td>1.348517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>0.575529</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>0.941835</td>\n",
       "      <td>0.792882</td>\n",
       "      <td>1.414277</td>\n",
       "      <td>1.269540</td>\n",
       "      <td>1.055928</td>\n",
       "      <td>0.713193</td>\n",
       "      <td>0.958684</td>\n",
       "      <td>1.663489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>1.135470</td>\n",
       "      <td>0.982462</td>\n",
       "      <td>0.781905</td>\n",
       "      <td>0.916738</td>\n",
       "      <td>0.901031</td>\n",
       "      <td>0.884738</td>\n",
       "      <td>0.386802</td>\n",
       "      <td>0.389584</td>\n",
       "      <td>0.919191</td>\n",
       "      <td>1.385504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>1.084894</td>\n",
       "      <td>0.861769</td>\n",
       "      <td>0.407158</td>\n",
       "      <td>0.665696</td>\n",
       "      <td>1.608612</td>\n",
       "      <td>0.943859</td>\n",
       "      <td>0.855806</td>\n",
       "      <td>1.061338</td>\n",
       "      <td>1.277456</td>\n",
       "      <td>1.188063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0.837460</td>\n",
       "      <td>0.961184</td>\n",
       "      <td>0.417006</td>\n",
       "      <td>0.799784</td>\n",
       "      <td>0.934399</td>\n",
       "      <td>0.424762</td>\n",
       "      <td>0.778234</td>\n",
       "      <td>0.907962</td>\n",
       "      <td>1.257190</td>\n",
       "      <td>1.364837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       WTT       PTI       EQW       SBI       LQE       QWG  \\\n",
       "0             0  0.913917  1.162073  0.567946  0.755464  0.780862  0.352608   \n",
       "1             1  0.635632  1.003722  0.535342  0.825645  0.924109  0.648450   \n",
       "2             2  0.721360  1.201493  0.921990  0.855595  1.526629  0.720781   \n",
       "3             3  1.234204  1.386726  0.653046  0.825624  1.142504  0.875128   \n",
       "4             4  1.279491  0.949750  0.627280  0.668976  1.232537  0.703727   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "995         995  1.010953  1.034006  0.853116  0.622460  1.036610  0.586240   \n",
       "996         996  0.575529  0.955786  0.941835  0.792882  1.414277  1.269540   \n",
       "997         997  1.135470  0.982462  0.781905  0.916738  0.901031  0.884738   \n",
       "998         998  1.084894  0.861769  0.407158  0.665696  1.608612  0.943859   \n",
       "999         999  0.837460  0.961184  0.417006  0.799784  0.934399  0.424762   \n",
       "\n",
       "          FDJ       PJF       HQE       NXJ  TARGET CLASS  \n",
       "0    0.759697  0.643798  0.879422  1.231409             1  \n",
       "1    0.675334  1.013546  0.621552  1.492702             0  \n",
       "2    1.626351  1.154483  0.957877  1.285597             0  \n",
       "3    1.409708  1.380003  1.522692  1.153093             1  \n",
       "4    1.115596  0.646691  1.463812  1.419167             1  \n",
       "..        ...       ...       ...       ...           ...  \n",
       "995  0.746811  0.319752  1.117340  1.348517             1  \n",
       "996  1.055928  0.713193  0.958684  1.663489             0  \n",
       "997  0.386802  0.389584  0.919191  1.385504             1  \n",
       "998  0.855806  1.061338  1.277456  1.188063             1  \n",
       "999  0.778234  0.907962  1.257190  1.364837             1  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d9d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
